{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:34:25.973314Z",
     "start_time": "2024-07-08T19:34:25.961616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time"
   ],
   "id": "b153f00d79071e61",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:34:26.016152Z",
     "start_time": "2024-07-08T19:34:26.011088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('scraping.log', mode='w', encoding='utf-8'),\n",
    "        logging.StreamHandler()  # This will output logs to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('rag_project')"
   ],
   "id": "38b2d6784a445574",
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T19:34:26.060549Z",
     "start_time": "2024-07-08T19:34:26.045892Z"
    }
   },
   "source": [
    "def setup_driver():\n",
    "    logger.debug(\"Setting up the Chrome driver\")\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in background\n",
    "    service = Service('/Users/ethanvertal/Documents/chromedriver-mac-arm64/chromedriver')  # Update this path\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    logger.debug(\"Chrome driver setup complete\")\n",
    "    return driver\n",
    "\n",
    "def scrape_speech(url, driver):\n",
    "    logger.debug(f\"Scraping URL: {url}\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"transcript-inner\") or (By.CLASS_NAME, \"view-transcript\"))\n",
    "        )\n",
    "        logger.debug(f\"Page loaded successfully for {url}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error waiting for transcript elements on {url}: {str(e)}\")\n",
    "        return None, None\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        title = soup.find('h2', class_='presidential-speeches--title').text.strip()\n",
    "        logger.debug(f\"Title found: {title}\")\n",
    "    except AttributeError:\n",
    "        logger.error(f\"Title not found on {url}\")\n",
    "        title = \"Unknown Title\"\n",
    "    \n",
    "    transcript_div = soup.find('div', class_='transcript-inner') or soup.find('div', class_='view-transcript')\n",
    "    \n",
    "    if not transcript_div:\n",
    "        logger.error(f\"Transcript container not found on {url}\")\n",
    "        return title, \"\"\n",
    "    \n",
    "    if transcript_div.find_all('p'):\n",
    "        paragraphs = transcript_div.find_all('p')\n",
    "        full_transcript = ' '.join([p.text.strip() for p in paragraphs])\n",
    "    elif transcript_div.find_all('span'):\n",
    "        spans = transcript_div.find_all('span')\n",
    "        full_transcript = ' '.join([span.text.strip() for span in spans])\n",
    "    else:\n",
    "        full_transcript = transcript_div.decode_contents().replace('<br>', '\\n').strip()\n",
    "    \n",
    "    logger.debug(f\"Transcript scraped for {title}\")\n",
    "    return title, full_transcript\n",
    "\n",
    "def scrape_all_speeches(base_url):\n",
    "    driver = setup_driver()\n",
    "    speeches = []\n",
    "    \n",
    "    logger.debug(f\"Starting to scrape all speeches from base URL: {base_url}\")\n",
    "    driver.get(base_url)\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    links = driver.find_elements(By.XPATH, \"//div[@class='views-row']/a\")\n",
    "    speech_links = [link.get_attribute('href') for link in links]\n",
    "    logger.debug(f\"Found {len(speech_links)} speech links\")\n",
    "\n",
    "    for link in speech_links:\n",
    "        try:\n",
    "            title, transcript = scrape_speech(link, driver)\n",
    "            if title and transcript:\n",
    "                speeches.append({\n",
    "                    'title': title,\n",
    "                    'transcript': transcript,\n",
    "                    'url': link\n",
    "                })\n",
    "                logger.info(f\"Scraped: {title}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error scraping {link}: {str(e)}\")\n",
    "    \n",
    "    driver.quit()\n",
    "    logger.debug(\"Finished scraping all speeches\")\n",
    "    return speeches\n",
    "\n",
    "def save_to_csv(speeches, filename):\n",
    "    logger.debug(f\"Saving speeches to CSV file: {filename}\")\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['title', 'transcript', 'url'])\n",
    "        writer.writeheader()\n",
    "        for speech in speeches:\n",
    "            writer.writerow(speech)\n",
    "    logger.debug(\"Speeches saved to CSV file successfully\")\n"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:35:05.667218Z",
     "start_time": "2024-07-08T19:34:26.061930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_url = 'https://millercenter.org/the-presidency/presidential-speeches'\n",
    "speeches = scrape_all_speeches(base_url)\n",
    "    "
   ],
   "id": "a82e9107ac65c1cb",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:35:05.672801Z",
     "start_time": "2024-07-08T19:35:05.670221Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1a9987c67bd632e4",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:35:05.697712Z",
     "start_time": "2024-07-08T19:35:05.674407Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(data=speeches, columns=['title', 'transcript', 'url'])",
   "id": "37ccd7cfa2112011",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, transcript, url]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:35:05.699875Z",
     "start_time": "2024-07-08T19:35:05.698465Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f570756a7c01c68e",
   "outputs": [],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
